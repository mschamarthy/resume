<section class="section experiences-section">
    <h2 class="section-title"><i class="fa fa-briefcase"></i>Experiences</h2>
    
    <div class="item">
        <div class="meta">
            <div class="upper-row">
                <h3 class="job-title">Big Data Engineer (Contractor)</h3>
                <div class="time">Jan. 2017 - Present</div>
            </div><!--//upper-row-->
            <div class="company">Capital One, Rolling Meadows, IL</div>
        </div><!--//meta-->
        <div class="details">  
            <ul>
                <li>Proactively Designed, Architected & implemented a system for managing and running of Spark jobs on transient EMR using Python which is widely adopted by teams across the enterprise.</li>
                <li>Architected and implemented automated remote triggering of various stages in a distributed application system.</li>
                <li>Implemented distributed job monitoring and logging tools for the application.</li>
                <li>Developed and implemented duplicate address clustering algorithm using NLP techniques such as HMM & NER.</li>
                <li>Developed Hydrograph (open source tool) based ETL workflows for data (Address) filtering & migrations.</li>
                <li>Implemented custom maven plugins for automated artifact packaging and deployment to nexus.</li>
                <li>Automated the Infrastructure setup of various AWS resources including EC2, EMR, Lambda, SNS, SQS, etc.</li>
                <li>Mentored an Intern with design and development of Workflow visualization web app.</li>
            </ul>
        </div><!--//details-->
    </div><!--//item-->
    
    <div class="item">
        <div class="meta">
            <div class="upper-row">
                <h3 class="job-title">Big Data Engineer</h3>
                <div class="time">Jun. 2014 - Jul. 2015</div>
            </div><!--//upper-row-->
            <div class="company">Cerner Healthcare Pvt. Ltd., Bangalore, India</div>
        </div><!--//meta-->
        <div class="details">
            <ul>
                <li>Received an award for developing the in-house knowledge base and team competency on Apache Crunch.</li>
                <li>Designed and developed Hadoop analytical pipelines for Key Performance Indicators (KPIs) for hospital finances.</li>
                <li>Implemented high-quality ETL pipelines in Java, Hadoop and Apache Crunch.</li>
                <li>Proactively improved runtime from hours to minutes by business logic optimization for Hadoop cluster.</li>
                <li>Trained 6 associates on functional and technical aspects including Hadoop, Apache Crunch, GitHub, SOLR.</li>
                <li>Released artifacts and deployed REST services, web servers and ETL pipelines using Chef.</li>
            </ul>
            
        </div><!--//details-->
    </div><!--//item-->
    
</section><!--//section-->